{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW6 (20')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "    \n",
    "Please submit your assignment as an HTML or PDF file.\n",
    "\n",
    "Print your name (First and Last) below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gahyun Lim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "    \n",
    "Import the `pandas`, `matplotlib.pyplot`, `numpy`, `scipy` libraries and assign them with proper nicknames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not delete this code section.\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Write a function that output marginal summary statistics and missing values for continuous variable (10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "**Write the function with `def`** (6')\n",
    "- Given a vector of continuous measure, you are asked to write a function named `fn_marginal_continuous`.\n",
    "- The function has one parameter `input_vec` and outputs a list of summary measure and the number of missing values.\n",
    "- Check the missingness of the `input_vec` using `np.isnan()` or `pd.isna()` functions.\n",
    "    - In our first case, we will assume the `input_vec` is an numpy array with missing values marked with `np.nan`.\n",
    "- The list of summary measure can be either **(mean, std)** or **(median, q1, q3)** depending on the normality assumption.\n",
    "    - To determine the normality assumption, you can rely on the p-value of the Shapiro-Wilk test.\n",
    "    - Relevant functions can be found here: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.shapiro.html \n",
    "    - If the p-value < 0.05, it is not normally distributed, otherwise, you can treat it as normally distributed.\n",
    "    - Think about what measure to report based on the normality assumption.\n",
    "    - Part of relevant functions can be found here: https://numpy.org/doc/2.0/reference/generated/numpy.nanmean.html\n",
    "- The return statement should include two components: `missing_num` and `output_ls` (your summmary measure).\n",
    "    - The missing numbers should be of type `int` instead of `np.int64`, and summary values should be of type `float` instead of `np.float64`.\n",
    "    - Round all your summary values such that they have no more than **3** digits after the decimals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_marginal_continuous(input_vec):\n",
    "    pass\n",
    "    missing_num = int(np.sum(np.isnan(input_vec)))  \n",
    "    clean_vec = input_vec[~np.isnan(input_vec)]\n",
    "    p_value = stats.shapiro(clean_vec).pvalue\n",
    "    if p_value >= 0.05:\n",
    "        output_ls = [float(round(np.mean(clean_vec), 3)),\n",
    "                     float(round(np.std(clean_vec, ddof=1), 3))]\n",
    "    else:\n",
    "        output_ls = [float(round(np.median(clean_vec), 3)),\n",
    "                     float(round(np.percentile(clean_vec, 25), 3)),\n",
    "                     float(round(np.percentile(clean_vec, 75), 3))]\n",
    "    return missing_num, output_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "**Test your function with the following different arguments:** (4') <br>\n",
    "For each scenario, please export the results as `missing_num_x`, `output_ls_x` and print them out separately.\n",
    "1. A standard normal random vector with a sample size of 100, named `input_vec_1`.\n",
    "2. A Chi-squared random vector with a degree of freedom 1 and a sample size of 100, named `input_vec_2`.\n",
    "3. Change the first element of `input_vec_1` as `np.nan` and create a new array named `input_vec_3`.\n",
    "    - Note that to create a copy of an numpy array, use `np.copy()` first.\n",
    "4. Change the last element of `input_vec_2` as `np.nan` and create a new array named `input_vec_4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [-0.104, 0.975]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(100) \n",
    "input_vec_1 = np.random.normal(loc=0, scale=1, size=100)\n",
    "missing_num_1, output_ls_1 = fn_marginal_continuous(input_vec_1)\n",
    "print (missing_num_1, output_ls_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.43, 0.089, 1.184]\n"
     ]
    }
   ],
   "source": [
    "input_vec_2 = np.random.chisquare(df=1, size=100)\n",
    "missing_num_2, output_ls_2 = fn_marginal_continuous(input_vec_2)\n",
    "print (missing_num_2, output_ls_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [-0.088, 0.965]\n"
     ]
    }
   ],
   "source": [
    "input_vec_3 = np.copy(input_vec_1)\n",
    "input_vec_3[0] = np.nan\n",
    "missing_num_3, output_ls_3 = fn_marginal_continuous(input_vec_3)\n",
    "print (missing_num_3, output_ls_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [0.422, 0.088, 1.19]\n"
     ]
    }
   ],
   "source": [
    "input_vec_4 = np.copy(input_vec_2)\n",
    "input_vec_4[-1] = np.nan\n",
    "missing_num_4, output_ls_4 = fn_marginal_continuous(input_vec_4)\n",
    "print (missing_num_4, output_ls_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Write a function that output marginal summary statistics and missing values for categorical variable (5')\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "**Write the function with `def`**\n",
    "- Given a column vector, you are asked to write a function named `fn_marginal_categorical`.\n",
    "- The function has one parameter named `input_vec` and outputs a list of summary measure and the number of missing values.\n",
    "- Check the missingness of the `input_vec` using `np.isnan()` or `pd.isna()` functions.\n",
    "    - In our second case, we will assume the `input_vec` is a column from a pandas DataFrame with missing values marked with `np.nan`.\n",
    "    - You can use both functions to identify missing values and yield the number of missingness.\n",
    "    - Use `pd.Series.value_counts()` function to obtain the frequency and proportion of `input_vec`, denoted as `tab_count` and `tab_percent`, respectively.\n",
    "    - Details can be found here: https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html\n",
    "    - For proportion, please use percentage (0-100%). You can ignore % when reporting.\n",
    "- The return statement should include two components: `missing_num` and `output_tab` (your summmary measure).\n",
    "    - For your `output_tab`, combine the count and proportion together using `pd.concat()`. Your `output_tab` should have three columns: variable name, count, and proportion.\n",
    "    - Details can be found here: https://pandas.pydata.org/docs/reference/api/pandas.concat.html\n",
    "    - The missing numbers should be of type `int` instead of `np.int64`, and percentgae values should be of type `float` instead of `np.float64`.\n",
    "    - Round all your relevant summary values such that they have no more than **2** digits after the decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_marginal_categorical(input_vec):\n",
    "    pass\n",
    "    missing_num = int(np.sum(pd.isna(input_vec)))  \n",
    "    tab_count = input_vec.value_counts(dropna=True)\n",
    "    tab_percent = (input_vec.value_counts(normalize=True, dropna=True) * 100).round(2)\n",
    "    output_tab = pd.concat([tab_count, tab_percent], axis=1)\n",
    "    output_tab.columns = ['count', 'proportion']\n",
    "    return missing_num, output_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test your written functions with a real dataset. (3')\n",
    "\n",
    "<font size='4'>\n",
    "    \n",
    "**Test the summary function for the continuous measure** (1')\n",
    "- Load the `PTSD dataset.xlsx` and name it as `ptsd_df`.\n",
    "    - The dataset should be stored under `data` folder when you sync changes and fetch origins the GitHub repository.\n",
    "- Use the column `pcl5month_score.baseline` as the input vector. This is a continuous measure.\n",
    "- Extract the corresponding column and give it a name `pcl5month_base`.\n",
    "- (*Optional*) You convert from a pandas.dataframe to an numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptsd_df = pd.read_excel('data/PTSD dataset.xlsx', sheet_name='main_dataset') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 [51.0, 42.0, 62.0]\n"
     ]
    }
   ],
   "source": [
    "pcl5month_base = ptsd_df['pcl5month_score.baseline']\n",
    "missing_num, output_ls = fn_marginal_continuous(pcl5month_base)\n",
    "print(missing_num, output_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "**Test the summary function for the categorical measure** (2')\n",
    "\n",
    "- Use the column `mdd_code` as the input vector. This is a binary vector.\n",
    "1. Extract the corresponding column and give it a name `mdd_code_vec`. Output your results as `missing_num_1` and `tab_1`. Print each element out (You will write `print()` twice).\n",
    "2. Create a copy of `mdd_code_vec` and name it as `mdd_code_vec_2`. Change its first element to `NaN`.\n",
    "    - Rerun the `fn_marginal_categorical()` with the new vector. Output your results as `missing_num_2` and `tab_2`. Print each element out (You will write `print()` twice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "          count  proportion\n",
      "mdd_code                   \n",
      "0           340       70.39\n",
      "1           143       29.61\n"
     ]
    }
   ],
   "source": [
    "mdd_code_vec = ptsd_df['mdd_code']\n",
    "missing_num_1, tab_1 = fn_marginal_categorical(mdd_code_vec)\n",
    "print(missing_num_1)\n",
    "print(tab_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "          count  proportion\n",
      "mdd_code                   \n",
      "0.0         339       70.33\n",
      "1.0         143       29.67\n"
     ]
    }
   ],
   "source": [
    "mdd_code_vec_2 = mdd_code_vec.copy()\n",
    "mdd_code_vec_2.iloc[0] = np.nan\n",
    "missing_num_2, tab_2 = fn_marginal_categorical(mdd_code_vec_2)\n",
    "print(missing_num_2)\n",
    "print(tab_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Lambda functions and for loop (2')\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "- Create a ``` lambda ``` function that checks if column `pcl5_score_intake` is greater than 30, denoted as `fn_pcl5_ptsd_check`.\n",
    "- Create a new list `pcl5_score_intake_ls` that shows `True` if `pcl5_score_intake`>30 and `False` otherwise using a for loop.\n",
    "    - You can also try `map()` function to iterate the function over `pcl5_score_intake`.\n",
    "    - Syntax is simple: `map(function_name, iterable, ...)`. \n",
    "- Print out the number of patients with `pcl5_score_intake` over 30 and mark them as **Clinically Significant for PTSD**.\n",
    "    - Your output can be something like `XXX out of YYY patients (ZZZ%) were marked as clinically significant for PTSD.`\n",
    "    - Round your percentage with no more than **2** decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451 out of 483 patients (93.37%) were marked as clinically significant for PTSD.\n"
     ]
    }
   ],
   "source": [
    "fn_pcl5_ptsd_check = lambda x: x > 30\n",
    "\n",
    "pcl5_score_intake_ls = []\n",
    "for score in ptsd_df['pcl5_score_intake']:\n",
    "    pcl5_score_intake_ls.append(fn_pcl5_ptsd_check(score))\n",
    "\n",
    "number = sum(pcl5_score_intake_ls)\n",
    "total = len(pcl5_score_intake_ls)\n",
    "percent = round((number / total) * 100, 2)\n",
    "\n",
    "print(f\"{number} out of {total} patients ({percent}%) were marked as clinically significant for PTSD.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "45fc1f684f6f416f40889115beff3ddf69879b64cf4bfee48cb72a61e9d15d1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
